{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Jn_uNyBoYnS_",
        "iQArva2pYrg_",
        "sPaaKTGwlk7a",
        "rnKLoiAtzr87"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Import**"
      ],
      "metadata": {
        "id": "Jn_uNyBoYnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "313HpTvqw17j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9345a32f-570e-46cd-c44a-e9c52cfdd2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VygOqTK6uzOI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "import optuna\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_seq_items', None)\n",
        "pd.set_option('display.max_info_columns', 200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61lLMhscu8-k",
        "outputId": "4161d532-8aff-42c5-c1f2-74d58a9e3d83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVS2g-MCvDMv",
        "outputId": "2274a0bc-56de-4eb0-8695-9b4e03b31ffd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**"
      ],
      "metadata": {
        "id": "iQArva2pYrg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/Semester 3/DL/Shiv/final_df.pkl\")"
      ],
      "metadata": {
        "id": "4Sb8XMuJwGzx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\n",
        "       'image',\n",
        "       'ViewPosition',\n",
        "       'Pneumonia',\n",
        "       ]].copy()"
      ],
      "metadata": {
        "id": "MXmNpXZCvFmN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model using CNN**\n"
      ],
      "metadata": {
        "id": "sPaaKTGwlk7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"ViewPosition\"] = df[\"ViewPosition\"].fillna(\"Unknown\")\n",
        "df[\"view_position_id\"] = df[\"ViewPosition\"].astype(\"category\").cat.codes\n",
        "n_view_positions = df[\"view_position_id\"].nunique()\n",
        "print(\"Number of distinct view positions:\", n_view_positions)\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.3,\n",
        "    stratify=df[\"Pneumonia\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"Pneumonia\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
        "print(\"Train label distribution:\\n\", train_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "print(\"Val label distribution:\\n\", val_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "print(\"Test label distribution:\\n\", test_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "\n",
        "\n",
        "class XrayImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Returns: image_tensor, label, view_position_id\n",
        "    - image_tensor: FloatTensor [3, 320, 320] (already normalized)\n",
        "    - label: FloatTensor scalar (0.0 or 1.0)\n",
        "    - view_position_id: LongTensor scalar (0..n_view_positions-1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, augment: bool = False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _to_tensor_chw(self, img):\n",
        "\n",
        "        if torch.is_tensor(img):\n",
        "            x = img.detach().float()\n",
        "        elif isinstance(img, np.ndarray):\n",
        "            x = torch.from_numpy(img).float()\n",
        "        else:\n",
        "            raise TypeError(f\"Unsupported image type: {type(img)}\")\n",
        "\n",
        "        while x.ndim > 3:\n",
        "            x = x.squeeze(0)\n",
        "\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(0)\n",
        "        elif x.ndim == 3:\n",
        "            if x.shape[0] not in (1, 3) and x.shape[-1] in (1, 3):\n",
        "                x = x.permute(2, 0, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected image shape: {x.shape}\")\n",
        "\n",
        "        C, H, W = x.shape\n",
        "\n",
        "        if C == 1:\n",
        "            x = x.repeat(3, 1, 1)\n",
        "        elif C > 3:\n",
        "            x = x[:3]\n",
        "\n",
        "        if (H, W) != (320, 320):\n",
        "            x = F.interpolate(\n",
        "                x.unsqueeze(0), size=(320, 320), mode=\"bilinear\", align_corners=False\n",
        "            ).squeeze(0)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _augment_tensor(self, x):\n",
        "\n",
        "        if not self.augment:\n",
        "            return x\n",
        "\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "            x = torch.flip(x, dims=[2])\n",
        "\n",
        "        k = torch.randint(0, 4, (1,)).item()\n",
        "        if k > 0:\n",
        "            x = torch.rot90(x, k, dims=[1, 2])\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_data = row[\"image\"]\n",
        "        label = row[\"Pneumonia\"]\n",
        "        view_id = row[\"view_position_id\"]\n",
        "\n",
        "        x = self._to_tensor_chw(img_data)\n",
        "        x = self._augment_tensor(x)\n",
        "\n",
        "        y = torch.tensor(label, dtype=torch.float32)\n",
        "        view_id = torch.tensor(view_id, dtype=torch.long)\n",
        "\n",
        "        return x, y, view_id\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = XrayImageDataset(train_df, augment=True)\n",
        "val_dataset   = XrayImageDataset(val_df,   augment=False)\n",
        "test_dataset  = XrayImageDataset(test_df,  augment=False)\n",
        "\n",
        "# Default loaders\n",
        "default_batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=default_batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=default_batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=default_batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int = 3,\n",
        "        num_blocks: int = 3,\n",
        "        base_filters: int = 32,\n",
        "        dropout_conv: float = 0.0,\n",
        "        dropout_fc: float = 0.0,\n",
        "        fc_hidden_dim: int = 128,\n",
        "        n_view_positions: int = 3,\n",
        "        view_emb_dim: int = 8,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        #  Convolutional blocks\n",
        "        conv_layers = []\n",
        "        curr_in = in_channels\n",
        "        for b in range(num_blocks):\n",
        "            out_ch = base_filters * (2**b)\n",
        "            conv_layers.append(nn.Conv2d(curr_in, out_ch, kernel_size=3, padding=1))\n",
        "            conv_layers.append(nn.BatchNorm2d(out_ch))\n",
        "            conv_layers.append(nn.ReLU(inplace=True))\n",
        "            if dropout_conv > 0.0:\n",
        "                conv_layers.append(nn.Dropout2d(dropout_conv))\n",
        "            conv_layers.append(nn.MaxPool2d(2, 2))\n",
        "            curr_in = out_ch\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(*conv_layers)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        final_conv_ch = base_filters * (2 ** (num_blocks - 1))\n",
        "\n",
        "        #   view_position embedding\n",
        "        self.view_emb = nn.Embedding(num_embeddings=n_view_positions,\n",
        "                                     embedding_dim=view_emb_dim)\n",
        "\n",
        "        #   Fully connected head\n",
        "        fc_in_dim = final_conv_ch + view_emb_dim\n",
        "\n",
        "        if fc_hidden_dim is not None and fc_hidden_dim > 0:\n",
        "            self.fc_layers = nn.Sequential(\n",
        "                nn.Linear(fc_in_dim, fc_hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_fc) if dropout_fc > 0 else nn.Identity(),\n",
        "                nn.Linear(fc_hidden_dim, 1),\n",
        "            )\n",
        "        else:\n",
        "            self.fc_layers = nn.Linear(fc_in_dim, 1)\n",
        "\n",
        "    def forward(self, x, view_ids):\n",
        "        x = self.conv_blocks(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        v = self.view_emb(view_ids)\n",
        "        f = torch.cat([x, v], dim=1)\n",
        "        logits = self.fc_layers(f)\n",
        "        return logits\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    num_epochs: int = 20,\n",
        "    early_stopping_patience: int = 5,\n",
        "):\n",
        "    model.to(device)\n",
        "    best_val_auc = 0.0\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        #   TRAIN\n",
        "        model.train()\n",
        "        train_loss_sum = 0.0\n",
        "\n",
        "        for X, y, view_ids in train_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            view_ids = view_ids.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X, view_ids)\n",
        "            loss = criterion(logits.view(-1), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "        avg_train_loss = train_loss_sum / len(train_loader.dataset)\n",
        "\n",
        "        #   VALIDATION\n",
        "        model.eval()\n",
        "        val_loss_sum = 0.0\n",
        "        all_logits = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y, view_ids in val_loader:\n",
        "                X = X.to(device)\n",
        "                y = y.to(device)\n",
        "                view_ids = view_ids.to(device)\n",
        "\n",
        "                logits = model(X, view_ids)\n",
        "                loss = criterion(logits.view(-1), y)\n",
        "                val_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "                all_logits.append(logits.view(-1).cpu())\n",
        "                all_targets.append(y.cpu())\n",
        "\n",
        "        avg_val_loss = val_loss_sum / len(val_loader.dataset)\n",
        "        all_logits = torch.cat(all_logits)\n",
        "        all_targets = torch.cat(all_targets)\n",
        "\n",
        "        val_probs = torch.sigmoid(all_logits)\n",
        "        val_pred = (val_probs >= 0.5).int()\n",
        "\n",
        "        val_acc = accuracy_score(all_targets.numpy(), val_pred.numpy())\n",
        "        try:\n",
        "            val_auc = roc_auc_score(all_targets.numpy(), val_probs.numpy())\n",
        "        except ValueError:\n",
        "            val_auc = 0.0\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch}: \"\n",
        "            f\"Train Loss {avg_train_loss:.4f} | \"\n",
        "            f\"Val Loss {avg_val_loss:.4f} | \"\n",
        "            f\"Val Acc {val_acc:.4f} | \"\n",
        "            f\"Val ROC-AUC {val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        #   Early stopping\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, best_val_auc\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameter search space\n",
        "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    num_blocks = trial.suggest_int(\"num_blocks\", 2, 4)\n",
        "    base_filters = trial.suggest_categorical(\"base_filters\", [16, 32, 64])\n",
        "    dropout_conv = trial.suggest_categorical(\"dropout_conv\", [0.0, 0.2, 0.5])\n",
        "    dropout_fc = trial.suggest_categorical(\"dropout_fc\", [0.0, 0.3, 0.5])\n",
        "    fc_hidden_dim = trial.suggest_categorical(\"fc_hidden_dim\", [0, 64, 128, 256])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "\n",
        "    model = CustomCNN(\n",
        "        in_channels=3,\n",
        "        num_blocks=num_blocks,\n",
        "        base_filters=base_filters,\n",
        "        dropout_conv=dropout_conv,\n",
        "        dropout_fc=dropout_fc,\n",
        "        fc_hidden_dim=fc_hidden_dim,\n",
        "        n_view_positions=n_view_positions,\n",
        "        view_emb_dim=8,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Trial-specific loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model, best_val_auc = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        num_epochs=15,\n",
        "        early_stopping_patience=3,\n",
        "    )\n",
        "\n",
        "    return best_val_auc\n",
        "\n",
        "\n",
        "# Create and run study\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best validation ROC-AUC:\", study.best_value)\n",
        "\n",
        "\n",
        "best_params = study.best_params\n",
        "print(\"Training final model with best params:\", best_params)\n",
        "\n",
        "val_dataset  = XrayImageDataset(val_df,  augment=False)\n",
        "test_dataset = XrayImageDataset(test_df, augment=False)\n",
        "\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=best_params[\"batch_size\"], shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
        "\n",
        "train_val_df = pd.concat([train_df, val_df]).reset_index(drop=True)\n",
        "train_val_dataset = XrayImageDataset(train_val_df, augment=True)\n",
        "train_val_loader  = DataLoader(\n",
        "    train_val_dataset,\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "final_model = CustomCNN(\n",
        "    in_channels=3,\n",
        "    num_blocks=best_params[\"num_blocks\"],\n",
        "    base_filters=best_params[\"base_filters\"],\n",
        "    dropout_conv=best_params[\"dropout_conv\"],\n",
        "    dropout_fc=best_params[\"dropout_fc\"],\n",
        "    fc_hidden_dim=best_params[\"fc_hidden_dim\"],\n",
        "    n_view_positions=n_view_positions,\n",
        "    view_emb_dim=8,\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    final_model.parameters(),\n",
        "    lr=best_params[\"learning_rate\"],\n",
        "    weight_decay=best_params.get(\"weight_decay\", 0.0),\n",
        ")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "final_model, _ = train_model(\n",
        "    model=final_model,\n",
        "    train_loader=train_val_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    num_epochs=10,\n",
        "    early_stopping_patience=3,\n",
        ")\n",
        "\n",
        "#   Test evaluation\n",
        "final_model.eval()\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "test_loss_sum = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y, view_ids in test_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        view_ids = view_ids.to(device)\n",
        "\n",
        "        logits = final_model(X, view_ids)\n",
        "        loss = criterion(logits.view(-1), y)\n",
        "        test_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "        all_logits.append(logits.view(-1).cpu())\n",
        "        all_labels.append(y.cpu())\n",
        "\n",
        "all_logits = torch.cat(all_logits)\n",
        "all_labels = torch.cat(all_labels)\n",
        "\n",
        "test_loss = test_loss_sum / len(test_loader.dataset)\n",
        "test_probs = torch.sigmoid(all_logits)\n",
        "test_pred  = (test_probs >= 0.5).int()\n",
        "\n",
        "test_acc  = accuracy_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_prec = precision_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_rec  = recall_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_f1   = f1_score(all_labels.numpy(), test_pred.numpy())\n",
        "try:\n",
        "    test_auc = roc_auc_score(all_labels.numpy(), test_probs.numpy())\n",
        "except ValueError:\n",
        "    test_auc = 0.0\n",
        "\n",
        "cm = confusion_matrix(all_labels.numpy(), test_pred.numpy())\n",
        "report = classification_report(all_labels.numpy(), test_pred.numpy(),\n",
        "                               target_names=[\"Normal\", \"Pneumonia\"])\n",
        "\n",
        "print(f\"\\n=== Test Results ===\")\n",
        "print(f\"Test Loss:      {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"Test ROC-AUC:   {test_auc:.4f}\")\n",
        "print(f\"Test Precision: {test_prec:.4f}\")\n",
        "print(f\"Test Recall:    {test_rec:.4f}\")\n",
        "print(f\"Test F1-score:  {test_f1:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDNXPggpSRQn",
        "outputId": "b972f9c3-0ca7-4b5d-b65a-eee97160212d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:42:38,470] A new study created in memory with name: no-name-5ee8b621-9b95-4c91-ba64-02a1362f8672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct view positions: 2\n",
            "Train size: 1734, Val size: 372, Test size: 372\n",
            "Train label distribution:\n",
            " Pneumonia\n",
            "0    0.531142\n",
            "1    0.468858\n",
            "Name: proportion, dtype: float64\n",
            "Val label distribution:\n",
            " Pneumonia\n",
            "0    0.52957\n",
            "1    0.47043\n",
            "Name: proportion, dtype: float64\n",
            "Test label distribution:\n",
            " Pneumonia\n",
            "0    0.532258\n",
            "1    0.467742\n",
            "Name: proportion, dtype: float64\n",
            "Using device: cuda\n",
            "Epoch 1: Train Loss 0.7015 | Val Loss 0.6978 | Val Acc 0.4758 | Val ROC-AUC 0.4456\n",
            "Epoch 2: Train Loss 0.6998 | Val Loss 0.6954 | Val Acc 0.4624 | Val ROC-AUC 0.4848\n",
            "Epoch 3: Train Loss 0.6957 | Val Loss 0.6958 | Val Acc 0.4624 | Val ROC-AUC 0.4745\n",
            "Epoch 4: Train Loss 0.6961 | Val Loss 0.6956 | Val Acc 0.5296 | Val ROC-AUC 0.4414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:43:26,707] Trial 0 finished with value: 0.4848150833937636 and parameters: {'learning_rate': 0.0002569335732560429, 'batch_size': 8, 'num_blocks': 4, 'base_filters': 16, 'dropout_conv': 0.5, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 1.9191223837893584e-06}. Best is trial 0 with value: 0.4848150833937636.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6941 | Val Loss 0.6966 | Val Acc 0.5269 | Val ROC-AUC 0.4654\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6921 | Val Loss 0.6897 | Val Acc 0.5296 | Val ROC-AUC 0.5603\n",
            "Epoch 2: Train Loss 0.6908 | Val Loss 0.6899 | Val Acc 0.5296 | Val ROC-AUC 0.5214\n",
            "Epoch 3: Train Loss 0.6896 | Val Loss 0.6903 | Val Acc 0.5296 | Val ROC-AUC 0.5050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:44:03,997] Trial 1 finished with value: 0.5602610587382162 and parameters: {'learning_rate': 1.59491200702303e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 8.171167539691874e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6891 | Val Loss 0.6906 | Val Acc 0.5269 | Val ROC-AUC 0.5088\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6922 | Val Loss 0.6918 | Val Acc 0.5269 | Val ROC-AUC 0.5067\n",
            "Epoch 2: Train Loss 0.6928 | Val Loss 0.6925 | Val Acc 0.5242 | Val ROC-AUC 0.4770\n",
            "Epoch 3: Train Loss 0.6911 | Val Loss 0.6934 | Val Acc 0.5215 | Val ROC-AUC 0.4783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:45:04,097] Trial 2 finished with value: 0.506686004350979 and parameters: {'learning_rate': 3.382672802249835e-05, 'batch_size': 16, 'num_blocks': 2, 'base_filters': 64, 'dropout_conv': 0.2, 'dropout_fc': 0.0, 'fc_hidden_dim': 256, 'weight_decay': 2.1939171107064133e-05}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6886 | Val Loss 0.6947 | Val Acc 0.5134 | Val ROC-AUC 0.4717\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6909 | Val Loss 0.6935 | Val Acc 0.5269 | Val ROC-AUC 0.4502\n",
            "Epoch 2: Train Loss 0.6972 | Val Loss 0.6934 | Val Acc 0.5242 | Val ROC-AUC 0.4586\n",
            "Epoch 3: Train Loss 0.6915 | Val Loss 0.6936 | Val Acc 0.5134 | Val ROC-AUC 0.4672\n",
            "Epoch 4: Train Loss 0.6913 | Val Loss 0.6937 | Val Acc 0.5134 | Val ROC-AUC 0.4693\n",
            "Epoch 5: Train Loss 0.6945 | Val Loss 0.6942 | Val Acc 0.5323 | Val ROC-AUC 0.4714\n",
            "Epoch 6: Train Loss 0.6954 | Val Loss 0.6949 | Val Acc 0.4812 | Val ROC-AUC 0.4694\n",
            "Epoch 7: Train Loss 0.6918 | Val Loss 0.6947 | Val Acc 0.4839 | Val ROC-AUC 0.4685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:47:07,898] Trial 3 finished with value: 0.4713850616388688 and parameters: {'learning_rate': 1.9557733047755227e-05, 'batch_size': 8, 'num_blocks': 2, 'base_filters': 64, 'dropout_conv': 0.2, 'dropout_fc': 0.3, 'fc_hidden_dim': 0, 'weight_decay': 2.014383824179275e-05}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss 0.6916 | Val Loss 0.6944 | Val Acc 0.4892 | Val ROC-AUC 0.4698\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.7594 | Val Loss 0.7010 | Val Acc 0.4919 | Val ROC-AUC 0.5125\n",
            "Epoch 2: Train Loss 0.7245 | Val Loss 0.6914 | Val Acc 0.5296 | Val ROC-AUC 0.5204\n",
            "Epoch 3: Train Loss 0.7063 | Val Loss 0.6968 | Val Acc 0.4651 | Val ROC-AUC 0.5428\n",
            "Epoch 4: Train Loss 0.7029 | Val Loss 0.6906 | Val Acc 0.5296 | Val ROC-AUC 0.5150\n",
            "Epoch 5: Train Loss 0.6946 | Val Loss 0.6951 | Val Acc 0.5269 | Val ROC-AUC 0.5260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:49:27,491] Trial 4 finished with value: 0.5428281363306745 and parameters: {'learning_rate': 0.00024961850108267986, 'batch_size': 8, 'num_blocks': 4, 'base_filters': 64, 'dropout_conv': 0.5, 'dropout_fc': 0.3, 'fc_hidden_dim': 0, 'weight_decay': 0.00021255057737159565}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6971 | Val Loss 0.6941 | Val Acc 0.5376 | Val ROC-AUC 0.5176\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6993 | Val Loss 0.6923 | Val Acc 0.5296 | Val ROC-AUC 0.4827\n",
            "Epoch 2: Train Loss 0.6985 | Val Loss 0.6924 | Val Acc 0.5296 | Val ROC-AUC 0.5113\n",
            "Epoch 3: Train Loss 0.6950 | Val Loss 0.6942 | Val Acc 0.4624 | Val ROC-AUC 0.4800\n",
            "Epoch 4: Train Loss 0.6941 | Val Loss 0.6939 | Val Acc 0.5376 | Val ROC-AUC 0.4859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:50:28,109] Trial 5 finished with value: 0.5112980420594634 and parameters: {'learning_rate': 0.00011465246937957472, 'batch_size': 32, 'num_blocks': 4, 'base_filters': 32, 'dropout_conv': 0.5, 'dropout_fc': 0.3, 'fc_hidden_dim': 64, 'weight_decay': 7.723015008704813e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6904 | Val Loss 0.6937 | Val Acc 0.5296 | Val ROC-AUC 0.4906\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6969 | Val Loss 0.7031 | Val Acc 0.5296 | Val ROC-AUC 0.5017\n",
            "Epoch 2: Train Loss 0.6912 | Val Loss 0.7035 | Val Acc 0.4570 | Val ROC-AUC 0.4772\n",
            "Epoch 3: Train Loss 0.6931 | Val Loss 0.6974 | Val Acc 0.5296 | Val ROC-AUC 0.5147\n",
            "Epoch 4: Train Loss 0.6914 | Val Loss 0.6985 | Val Acc 0.4785 | Val ROC-AUC 0.5099\n",
            "Epoch 5: Train Loss 0.6879 | Val Loss 0.7071 | Val Acc 0.4597 | Val ROC-AUC 0.5013\n",
            "Epoch 6: Train Loss 0.6931 | Val Loss 0.6956 | Val Acc 0.5108 | Val ROC-AUC 0.5206\n",
            "Epoch 7: Train Loss 0.6914 | Val Loss 0.6991 | Val Acc 0.5188 | Val ROC-AUC 0.4951\n",
            "Epoch 8: Train Loss 0.6897 | Val Loss 0.7027 | Val Acc 0.5296 | Val ROC-AUC 0.5194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:52:04,091] Trial 6 finished with value: 0.520638143582306 and parameters: {'learning_rate': 0.000524495086849499, 'batch_size': 8, 'num_blocks': 4, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.3, 'fc_hidden_dim': 0, 'weight_decay': 0.0006214881921960604}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss 0.6896 | Val Loss 0.6974 | Val Acc 0.5430 | Val ROC-AUC 0.5070\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6960 | Val Loss 0.6917 | Val Acc 0.5296 | Val ROC-AUC 0.5021\n",
            "Epoch 2: Train Loss 0.6911 | Val Loss 0.6937 | Val Acc 0.5296 | Val ROC-AUC 0.4667\n",
            "Epoch 3: Train Loss 0.6902 | Val Loss 0.6958 | Val Acc 0.5242 | Val ROC-AUC 0.4739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:52:24,549] Trial 7 finished with value: 0.5021319796954314 and parameters: {'learning_rate': 0.00015145305176850248, 'batch_size': 8, 'num_blocks': 2, 'base_filters': 16, 'dropout_conv': 0.2, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 2.3065159261214122e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6897 | Val Loss 0.6976 | Val Acc 0.5081 | Val ROC-AUC 0.4690\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6937 | Val Loss 0.6937 | Val Acc 0.5188 | Val ROC-AUC 0.5283\n",
            "Epoch 2: Train Loss 0.6939 | Val Loss 0.6931 | Val Acc 0.5296 | Val ROC-AUC 0.4918\n",
            "Epoch 3: Train Loss 0.6873 | Val Loss 0.6934 | Val Acc 0.5376 | Val ROC-AUC 0.5151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:53:07,733] Trial 8 finished with value: 0.5282668600435099 and parameters: {'learning_rate': 5.5167174400206335e-05, 'batch_size': 16, 'num_blocks': 4, 'base_filters': 32, 'dropout_conv': 0.2, 'dropout_fc': 0.5, 'fc_hidden_dim': 256, 'weight_decay': 3.4470176253288102e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6937 | Val Loss 0.6946 | Val Acc 0.5349 | Val ROC-AUC 0.5106\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6975 | Val Loss 0.6965 | Val Acc 0.5296 | Val ROC-AUC 0.4727\n",
            "Epoch 2: Train Loss 0.6955 | Val Loss 0.7004 | Val Acc 0.4677 | Val ROC-AUC 0.4847\n",
            "Epoch 3: Train Loss 0.6941 | Val Loss 0.6971 | Val Acc 0.5215 | Val ROC-AUC 0.4864\n",
            "Epoch 4: Train Loss 0.6899 | Val Loss 0.6975 | Val Acc 0.5296 | Val ROC-AUC 0.4842\n",
            "Epoch 5: Train Loss 0.6916 | Val Loss 0.6999 | Val Acc 0.5215 | Val ROC-AUC 0.4802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:53:36,284] Trial 9 finished with value: 0.4864104423495286 and parameters: {'learning_rate': 0.0003997644491461923, 'batch_size': 16, 'num_blocks': 2, 'base_filters': 16, 'dropout_conv': 0.0, 'dropout_fc': 0.5, 'fc_hidden_dim': 256, 'weight_decay': 0.0004908788267205851}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6892 | Val Loss 0.6995 | Val Acc 0.4946 | Val ROC-AUC 0.4828\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6966 | Val Loss 0.6955 | Val Acc 0.4731 | Val ROC-AUC 0.4732\n",
            "Epoch 2: Train Loss 0.6936 | Val Loss 0.6939 | Val Acc 0.4919 | Val ROC-AUC 0.4755\n",
            "Epoch 3: Train Loss 0.6912 | Val Loss 0.6931 | Val Acc 0.4866 | Val ROC-AUC 0.4697\n",
            "Epoch 4: Train Loss 0.6902 | Val Loss 0.6932 | Val Acc 0.4839 | Val ROC-AUC 0.4711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:54:29,603] Trial 10 finished with value: 0.47550398839738944 and parameters: {'learning_rate': 1.0455156137416902e-05, 'batch_size': 32, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 8.540942233652398e-05}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6898 | Val Loss 0.6930 | Val Acc 0.5000 | Val ROC-AUC 0.4738\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.7083 | Val Loss 0.7009 | Val Acc 0.4651 | Val ROC-AUC 0.4887\n",
            "Epoch 2: Train Loss 0.7032 | Val Loss 0.6998 | Val Acc 0.4651 | Val ROC-AUC 0.4814\n",
            "Epoch 3: Train Loss 0.7048 | Val Loss 0.6958 | Val Acc 0.4677 | Val ROC-AUC 0.5013\n",
            "Epoch 4: Train Loss 0.7090 | Val Loss 0.6961 | Val Acc 0.4624 | Val ROC-AUC 0.4985\n",
            "Epoch 5: Train Loss 0.7102 | Val Loss 0.6967 | Val Acc 0.4704 | Val ROC-AUC 0.5014\n",
            "Epoch 6: Train Loss 0.7127 | Val Loss 0.6992 | Val Acc 0.4651 | Val ROC-AUC 0.5013\n",
            "Epoch 7: Train Loss 0.7052 | Val Loss 0.6972 | Val Acc 0.4624 | Val ROC-AUC 0.4937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:56:57,741] Trial 11 finished with value: 0.5013923132704858 and parameters: {'learning_rate': 6.019966930266508e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 64, 'dropout_conv': 0.5, 'dropout_fc': 0.0, 'fc_hidden_dim': 0, 'weight_decay': 0.00010995316025666964}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss 0.7042 | Val Loss 0.6973 | Val Acc 0.4651 | Val ROC-AUC 0.4913\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.7039 | Val Loss 0.6949 | Val Acc 0.5349 | Val ROC-AUC 0.4784\n",
            "Epoch 2: Train Loss 0.6931 | Val Loss 0.6958 | Val Acc 0.4570 | Val ROC-AUC 0.5079\n",
            "Epoch 3: Train Loss 0.6925 | Val Loss 0.6937 | Val Acc 0.5296 | Val ROC-AUC 0.5193\n",
            "Epoch 4: Train Loss 0.6929 | Val Loss 0.6937 | Val Acc 0.5296 | Val ROC-AUC 0.5089\n",
            "Epoch 5: Train Loss 0.6919 | Val Loss 0.6939 | Val Acc 0.5296 | Val ROC-AUC 0.4921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 19:58:56,005] Trial 12 finished with value: 0.519303843364757 and parameters: {'learning_rate': 0.0009672410445894134, 'batch_size': 8, 'num_blocks': 3, 'base_filters': 64, 'dropout_conv': 0.5, 'dropout_fc': 0.3, 'fc_hidden_dim': 128, 'weight_decay': 0.00013950955796864062}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6899 | Val Loss 0.6939 | Val Acc 0.5296 | Val ROC-AUC 0.5088\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6917 | Val Loss 0.6987 | Val Acc 0.5296 | Val ROC-AUC 0.5100\n",
            "Epoch 2: Train Loss 0.6908 | Val Loss 0.6962 | Val Acc 0.5188 | Val ROC-AUC 0.5003\n",
            "Epoch 3: Train Loss 0.6887 | Val Loss 0.7016 | Val Acc 0.5296 | Val ROC-AUC 0.4998\n",
            "Epoch 4: Train Loss 0.6873 | Val Loss 0.6941 | Val Acc 0.4624 | Val ROC-AUC 0.5442\n",
            "Epoch 5: Train Loss 0.6866 | Val Loss 0.6960 | Val Acc 0.5269 | Val ROC-AUC 0.5304\n",
            "Epoch 6: Train Loss 0.6847 | Val Loss 0.6905 | Val Acc 0.5296 | Val ROC-AUC 0.5411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:00:56,603] Trial 13 finished with value: 0.5442204496011602 and parameters: {'learning_rate': 0.00019006803997512867, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 64, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 8.956983341495335e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss 0.6846 | Val Loss 0.6976 | Val Acc 0.5296 | Val ROC-AUC 0.5394\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6926 | Val Loss 0.6914 | Val Acc 0.5242 | Val ROC-AUC 0.4906\n",
            "Epoch 2: Train Loss 0.6904 | Val Loss 0.6916 | Val Acc 0.5027 | Val ROC-AUC 0.4844\n",
            "Epoch 3: Train Loss 0.6895 | Val Loss 0.6917 | Val Acc 0.5161 | Val ROC-AUC 0.4835\n",
            "Epoch 4: Train Loss 0.6892 | Val Loss 0.6914 | Val Acc 0.5134 | Val ROC-AUC 0.4956\n",
            "Epoch 5: Train Loss 0.6881 | Val Loss 0.6915 | Val Acc 0.5054 | Val ROC-AUC 0.4964\n",
            "Epoch 6: Train Loss 0.6879 | Val Loss 0.6917 | Val Acc 0.5269 | Val ROC-AUC 0.4975\n",
            "Epoch 7: Train Loss 0.6878 | Val Loss 0.6916 | Val Acc 0.5269 | Val ROC-AUC 0.5039\n",
            "Epoch 8: Train Loss 0.6870 | Val Loss 0.6916 | Val Acc 0.5215 | Val ROC-AUC 0.5064\n",
            "Epoch 9: Train Loss 0.6871 | Val Loss 0.6914 | Val Acc 0.5376 | Val ROC-AUC 0.5139\n",
            "Epoch 10: Train Loss 0.6868 | Val Loss 0.6912 | Val Acc 0.5511 | Val ROC-AUC 0.5143\n",
            "Epoch 11: Train Loss 0.6869 | Val Loss 0.6907 | Val Acc 0.5565 | Val ROC-AUC 0.5263\n",
            "Epoch 12: Train Loss 0.6862 | Val Loss 0.6906 | Val Acc 0.5565 | Val ROC-AUC 0.5276\n",
            "Epoch 13: Train Loss 0.6863 | Val Loss 0.6906 | Val Acc 0.5565 | Val ROC-AUC 0.5291\n",
            "Epoch 14: Train Loss 0.6854 | Val Loss 0.6910 | Val Acc 0.5538 | Val ROC-AUC 0.5234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:03:15,538] Trial 14 finished with value: 0.5291370558375634 and parameters: {'learning_rate': 1.1818257383057553e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 8.168727338738307e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss 0.6854 | Val Loss 0.6911 | Val Acc 0.5484 | Val ROC-AUC 0.5237\n",
            "Epoch 1: Train Loss 0.6902 | Val Loss 0.6937 | Val Acc 0.5323 | Val ROC-AUC 0.4778\n",
            "Epoch 2: Train Loss 0.6872 | Val Loss 0.6941 | Val Acc 0.5323 | Val ROC-AUC 0.4937\n",
            "Epoch 3: Train Loss 0.6869 | Val Loss 0.6952 | Val Acc 0.5323 | Val ROC-AUC 0.4969\n",
            "Epoch 4: Train Loss 0.6861 | Val Loss 0.6948 | Val Acc 0.5376 | Val ROC-AUC 0.5042\n",
            "Epoch 5: Train Loss 0.6862 | Val Loss 0.6937 | Val Acc 0.5242 | Val ROC-AUC 0.5143\n",
            "Epoch 6: Train Loss 0.6854 | Val Loss 0.6938 | Val Acc 0.5538 | Val ROC-AUC 0.5244\n",
            "Epoch 7: Train Loss 0.6850 | Val Loss 0.6939 | Val Acc 0.5457 | Val ROC-AUC 0.5212\n",
            "Epoch 8: Train Loss 0.6845 | Val Loss 0.6939 | Val Acc 0.5403 | Val ROC-AUC 0.5246\n",
            "Epoch 9: Train Loss 0.6829 | Val Loss 0.6915 | Val Acc 0.5618 | Val ROC-AUC 0.5416\n",
            "Epoch 10: Train Loss 0.6827 | Val Loss 0.6921 | Val Acc 0.5538 | Val ROC-AUC 0.5377\n",
            "Epoch 11: Train Loss 0.6828 | Val Loss 0.6909 | Val Acc 0.5430 | Val ROC-AUC 0.5525\n",
            "Epoch 12: Train Loss 0.6833 | Val Loss 0.6907 | Val Acc 0.5618 | Val ROC-AUC 0.5505\n",
            "Epoch 13: Train Loss 0.6824 | Val Loss 0.6901 | Val Acc 0.5242 | Val ROC-AUC 0.5553\n",
            "Epoch 14: Train Loss 0.6827 | Val Loss 0.6896 | Val Acc 0.5511 | Val ROC-AUC 0.5500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:05:34,433] Trial 15 finished with value: 0.55962291515591 and parameters: {'learning_rate': 6.372999710699547e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 8.217339793385306e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss 0.6799 | Val Loss 0.6875 | Val Acc 0.5645 | Val ROC-AUC 0.5596\n",
            "Epoch 1: Train Loss 0.6920 | Val Loss 0.6903 | Val Acc 0.5269 | Val ROC-AUC 0.5219\n",
            "Epoch 2: Train Loss 0.6897 | Val Loss 0.6910 | Val Acc 0.5161 | Val ROC-AUC 0.4947\n",
            "Epoch 3: Train Loss 0.6890 | Val Loss 0.6911 | Val Acc 0.5134 | Val ROC-AUC 0.4958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:06:11,490] Trial 16 finished with value: 0.5218564176939812 and parameters: {'learning_rate': 2.8567644388299535e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 1.091643239706025e-06}. Best is trial 1 with value: 0.5602610587382162.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6879 | Val Loss 0.6916 | Val Acc 0.5296 | Val ROC-AUC 0.4921\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6927 | Val Loss 0.6908 | Val Acc 0.5269 | Val ROC-AUC 0.4940\n",
            "Epoch 2: Train Loss 0.6895 | Val Loss 0.6909 | Val Acc 0.5054 | Val ROC-AUC 0.5086\n",
            "Epoch 3: Train Loss 0.6876 | Val Loss 0.6905 | Val Acc 0.5188 | Val ROC-AUC 0.5238\n",
            "Epoch 4: Train Loss 0.6868 | Val Loss 0.6903 | Val Acc 0.5323 | Val ROC-AUC 0.5218\n",
            "Epoch 5: Train Loss 0.6868 | Val Loss 0.6894 | Val Acc 0.5430 | Val ROC-AUC 0.5285\n",
            "Epoch 6: Train Loss 0.6860 | Val Loss 0.6899 | Val Acc 0.5323 | Val ROC-AUC 0.5312\n",
            "Epoch 7: Train Loss 0.6846 | Val Loss 0.6887 | Val Acc 0.5511 | Val ROC-AUC 0.5359\n",
            "Epoch 8: Train Loss 0.6841 | Val Loss 0.6898 | Val Acc 0.5242 | Val ROC-AUC 0.5354\n",
            "Epoch 9: Train Loss 0.6840 | Val Loss 0.6864 | Val Acc 0.5430 | Val ROC-AUC 0.5571\n",
            "Epoch 10: Train Loss 0.6847 | Val Loss 0.6864 | Val Acc 0.5538 | Val ROC-AUC 0.5581\n",
            "Epoch 11: Train Loss 0.6827 | Val Loss 0.6852 | Val Acc 0.5430 | Val ROC-AUC 0.5617\n",
            "Epoch 12: Train Loss 0.6825 | Val Loss 0.6867 | Val Acc 0.5457 | Val ROC-AUC 0.5477\n",
            "Epoch 13: Train Loss 0.6830 | Val Loss 0.6881 | Val Acc 0.5403 | Val ROC-AUC 0.5597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:08:21,068] Trial 17 finished with value: 0.5616823785351703 and parameters: {'learning_rate': 6.905064059372074e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 4.47879326895593e-05}. Best is trial 17 with value: 0.5616823785351703.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss 0.6816 | Val Loss 0.6903 | Val Acc 0.5430 | Val ROC-AUC 0.5475\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6922 | Val Loss 0.6960 | Val Acc 0.4651 | Val ROC-AUC 0.4263\n",
            "Epoch 2: Train Loss 0.6909 | Val Loss 0.6949 | Val Acc 0.4677 | Val ROC-AUC 0.4336\n",
            "Epoch 3: Train Loss 0.6902 | Val Loss 0.6949 | Val Acc 0.4624 | Val ROC-AUC 0.4381\n",
            "Epoch 4: Train Loss 0.6896 | Val Loss 0.6946 | Val Acc 0.5081 | Val ROC-AUC 0.4432\n",
            "Epoch 5: Train Loss 0.6893 | Val Loss 0.6945 | Val Acc 0.5054 | Val ROC-AUC 0.4441\n",
            "Epoch 6: Train Loss 0.6891 | Val Loss 0.6946 | Val Acc 0.5188 | Val ROC-AUC 0.4470\n",
            "Epoch 7: Train Loss 0.6887 | Val Loss 0.6949 | Val Acc 0.5188 | Val ROC-AUC 0.4479\n",
            "Epoch 8: Train Loss 0.6885 | Val Loss 0.6952 | Val Acc 0.5134 | Val ROC-AUC 0.4495\n",
            "Epoch 9: Train Loss 0.6883 | Val Loss 0.6952 | Val Acc 0.5242 | Val ROC-AUC 0.4504\n",
            "Epoch 10: Train Loss 0.6879 | Val Loss 0.6955 | Val Acc 0.5081 | Val ROC-AUC 0.4505\n",
            "Epoch 11: Train Loss 0.6880 | Val Loss 0.6959 | Val Acc 0.5134 | Val ROC-AUC 0.4530\n",
            "Epoch 12: Train Loss 0.6876 | Val Loss 0.6959 | Val Acc 0.5161 | Val ROC-AUC 0.4533\n",
            "Epoch 13: Train Loss 0.6878 | Val Loss 0.6959 | Val Acc 0.5269 | Val ROC-AUC 0.4542\n",
            "Epoch 14: Train Loss 0.6875 | Val Loss 0.6962 | Val Acc 0.5188 | Val ROC-AUC 0.4561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:10:37,241] Trial 18 finished with value: 0.45606961566352433 and parameters: {'learning_rate': 1.7741767506694658e-05, 'batch_size': 32, 'num_blocks': 2, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 4.3701412934605116e-05}. Best is trial 17 with value: 0.5616823785351703.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss 0.6872 | Val Loss 0.6961 | Val Acc 0.5188 | Val ROC-AUC 0.4557\n",
            "Epoch 1: Train Loss 0.6917 | Val Loss 0.6901 | Val Acc 0.5242 | Val ROC-AUC 0.5191\n",
            "Epoch 2: Train Loss 0.6891 | Val Loss 0.6905 | Val Acc 0.5161 | Val ROC-AUC 0.5072\n",
            "Epoch 3: Train Loss 0.6874 | Val Loss 0.6907 | Val Acc 0.5430 | Val ROC-AUC 0.5075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-07 20:11:14,266] Trial 19 finished with value: 0.5191007976794779 and parameters: {'learning_rate': 3.544986586260537e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 128, 'weight_decay': 4.5634739959686986e-05}. Best is trial 17 with value: 0.5616823785351703.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6871 | Val Loss 0.6903 | Val Acc 0.5430 | Val ROC-AUC 0.5163\n",
            "Early stopping triggered.\n",
            "Best hyperparameters: {'learning_rate': 6.905064059372074e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 4.47879326895593e-05}\n",
            "Best validation ROC-AUC: 0.5616823785351703\n",
            "Training final model with best params: {'learning_rate': 6.905064059372074e-05, 'batch_size': 16, 'num_blocks': 3, 'base_filters': 32, 'dropout_conv': 0.0, 'dropout_fc': 0.0, 'fc_hidden_dim': 64, 'weight_decay': 4.47879326895593e-05}\n",
            "Epoch 1: Train Loss 0.6914 | Val Loss 0.6903 | Val Acc 0.5215 | Val ROC-AUC 0.5258\n",
            "Epoch 2: Train Loss 0.6884 | Val Loss 0.6914 | Val Acc 0.5296 | Val ROC-AUC 0.5199\n",
            "Epoch 3: Train Loss 0.6881 | Val Loss 0.6888 | Val Acc 0.5538 | Val ROC-AUC 0.5463\n",
            "Epoch 4: Train Loss 0.6874 | Val Loss 0.6871 | Val Acc 0.5457 | Val ROC-AUC 0.5627\n",
            "Epoch 5: Train Loss 0.6872 | Val Loss 0.6874 | Val Acc 0.5618 | Val ROC-AUC 0.5506\n",
            "Epoch 6: Train Loss 0.6856 | Val Loss 0.6865 | Val Acc 0.5699 | Val ROC-AUC 0.5643\n",
            "Epoch 7: Train Loss 0.6846 | Val Loss 0.6849 | Val Acc 0.5726 | Val ROC-AUC 0.5742\n",
            "Epoch 8: Train Loss 0.6833 | Val Loss 0.6853 | Val Acc 0.5511 | Val ROC-AUC 0.5601\n",
            "Epoch 9: Train Loss 0.6857 | Val Loss 0.6870 | Val Acc 0.5457 | Val ROC-AUC 0.5588\n",
            "Epoch 10: Train Loss 0.6828 | Val Loss 0.6911 | Val Acc 0.4892 | Val ROC-AUC 0.5722\n",
            "Early stopping triggered.\n",
            "\n",
            "=== Test Results ===\n",
            "Test Loss:      0.6955\n",
            "Test Accuracy:  0.5188\n",
            "Test ROC-AUC:   0.5655\n",
            "Test Precision: 0.4915\n",
            "Test Recall:    0.8276\n",
            "Test F1-score:  0.6167\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 49 149]\n",
            " [ 30 144]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.62      0.25      0.35       198\n",
            "   Pneumonia       0.49      0.83      0.62       174\n",
            "\n",
            "    accuracy                           0.52       372\n",
            "   macro avg       0.56      0.54      0.49       372\n",
            "weighted avg       0.56      0.52      0.48       372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model using Resnet**"
      ],
      "metadata": {
        "id": "rnKLoiAtzr87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "import optuna\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "df[\"ViewPosition\"] = df[\"ViewPosition\"].fillna(\"Unknown\")\n",
        "df[\"view_position_id\"] = df[\"ViewPosition\"].astype(\"category\").cat.codes\n",
        "n_view_positions = df[\"view_position_id\"].nunique()\n",
        "print(\"Number of distinct view positions:\", n_view_positions)\n",
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.3,\n",
        "    stratify=df[\"Pneumonia\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"Pneumonia\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
        "print(\"Train label distribution:\\n\", train_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "print(\"Val label distribution:\\n\", val_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "print(\"Test label distribution:\\n\", test_df[\"Pneumonia\"].value_counts(normalize=True))\n",
        "\n",
        "\n",
        "class XrayImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Returns: image_tensor, label, view_position_id\n",
        "    - image_tensor: FloatTensor [3, 320, 320] (already normalized)\n",
        "    - label: FloatTensor scalar (0.0 or 1.0)\n",
        "    - view_position_id: LongTensor scalar (0..n_view_positions-1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, augment: bool = False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _to_tensor_chw(self, img):\n",
        "        \"\"\"\n",
        "        Convert df['image'] entry into FloatTensor [3, 320, 320].\n",
        "        Handles numpy arrays and torch tensors, with shapes like:\n",
        "        - [3, 320, 320]\n",
        "        - [1, 320, 320]\n",
        "        - [320, 320]\n",
        "        - [H, W, C]\n",
        "        etc.\n",
        "        Assumes intensities are ALREADY normalized; we do NOT re-normalize.\n",
        "        \"\"\"\n",
        "        # 1) to tensor\n",
        "        if torch.is_tensor(img):\n",
        "            x = img.detach().float()\n",
        "        elif isinstance(img, np.ndarray):\n",
        "            x = torch.from_numpy(img).float()\n",
        "        else:\n",
        "            raise TypeError(f\"Unsupported image type: {type(img)}\")\n",
        "\n",
        "        while x.ndim > 3:\n",
        "            x = x.squeeze(0)\n",
        "\n",
        "        if x.ndim == 2:\n",
        "            x = x.unsqueeze(0)\n",
        "        elif x.ndim == 3:\n",
        "            if x.shape[0] not in (1, 3) and x.shape[-1] in (1, 3):\n",
        "                x = x.permute(2, 0, 1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected image shape: {x.shape}\")\n",
        "\n",
        "        C, H, W = x.shape\n",
        "\n",
        "        if C == 1:\n",
        "            x = x.repeat(3, 1, 1)\n",
        "        elif C > 3:\n",
        "            x = x[:3]\n",
        "\n",
        "        if (H, W) != (320, 320):\n",
        "            x = F.interpolate(\n",
        "                x.unsqueeze(0), size=(320, 320), mode=\"bilinear\", align_corners=False\n",
        "            ).squeeze(0)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _augment_tensor(self, x):\n",
        "\n",
        "        if not self.augment:\n",
        "            return x\n",
        "\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "            x = torch.flip(x, dims=[2])\n",
        "\n",
        "        k = torch.randint(0, 4, (1,)).item()\n",
        "        if k > 0:\n",
        "            x = torch.rot90(x, k, dims=[1, 2])\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_data = row[\"image\"]\n",
        "        label = row[\"Pneumonia\"]\n",
        "        view_id = row[\"view_position_id\"]\n",
        "\n",
        "        x = self._to_tensor_chw(img_data)\n",
        "        x = self._augment_tensor(x)\n",
        "\n",
        "        y = torch.tensor(label, dtype=torch.float32)\n",
        "        view_id = torch.tensor(view_id, dtype=torch.long)\n",
        "\n",
        "        return x, y, view_id\n",
        "\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = XrayImageDataset(train_df, augment=True)\n",
        "val_dataset   = XrayImageDataset(val_df,   augment=False)\n",
        "test_dataset  = XrayImageDataset(test_df,  augment=False)\n",
        "\n",
        "# Default loaders\n",
        "default_batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=default_batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=default_batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=default_batch_size, shuffle=False)\n",
        "\n",
        "class ResNet18Custom(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_view_positions: int,\n",
        "        view_emb_dim: int = 8,\n",
        "        fc_hidden_dim: int = 128,\n",
        "        dropout_fc: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet = models.resnet18(weights=None)\n",
        "        self.resnet.fc = nn.Identity()\n",
        "\n",
        "        # view_position embedding\n",
        "        self.view_emb = nn.Embedding(\n",
        "            num_embeddings=n_view_positions,\n",
        "            embedding_dim=view_emb_dim,\n",
        "        )\n",
        "\n",
        "        # Fully connected head\n",
        "        feat_dim = 512\n",
        "        fc_in_dim = feat_dim + view_emb_dim\n",
        "\n",
        "        if fc_hidden_dim is not None and fc_hidden_dim > 0:\n",
        "            self.fc_layers = nn.Sequential(\n",
        "                nn.Linear(fc_in_dim, fc_hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_fc) if dropout_fc > 0 else nn.Identity(),\n",
        "                nn.Linear(fc_hidden_dim, 1),\n",
        "            )\n",
        "        else:\n",
        "            self.fc_layers = nn.Linear(fc_in_dim, 1)\n",
        "\n",
        "    def forward(self, x, view_ids):\n",
        "        img_feat = self.resnet(x)\n",
        "        img_feat = img_feat.view(img_feat.size(0), -1)\n",
        "\n",
        "        v = self.view_emb(view_ids)\n",
        "\n",
        "        f = torch.cat([img_feat, v], dim=1)\n",
        "        logits = self.fc_layers(f)\n",
        "        return logits\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    num_epochs: int = 20,\n",
        "    early_stopping_patience: int = 5,\n",
        "):\n",
        "    model.to(device)\n",
        "    best_val_auc = 0.0\n",
        "    best_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        #  TRAIN\n",
        "        model.train()\n",
        "        train_loss_sum = 0.0\n",
        "\n",
        "        for X, y, view_ids in train_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            view_ids = view_ids.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X, view_ids)\n",
        "            loss = criterion(logits.view(-1), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "        avg_train_loss = train_loss_sum / len(train_loader.dataset)\n",
        "\n",
        "        #  VALIDATION\n",
        "        model.eval()\n",
        "        val_loss_sum = 0.0\n",
        "        all_logits = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X, y, view_ids in val_loader:\n",
        "                X = X.to(device)\n",
        "                y = y.to(device)\n",
        "                view_ids = view_ids.to(device)\n",
        "\n",
        "                logits = model(X, view_ids)\n",
        "                loss = criterion(logits.view(-1), y)\n",
        "                val_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "                all_logits.append(logits.view(-1).cpu())\n",
        "                all_targets.append(y.cpu())\n",
        "\n",
        "        avg_val_loss = val_loss_sum / len(val_loader.dataset)\n",
        "        all_logits = torch.cat(all_logits)\n",
        "        all_targets = torch.cat(all_targets)\n",
        "\n",
        "        val_probs = torch.sigmoid(all_logits)\n",
        "        val_pred = (val_probs >= 0.5).int()\n",
        "\n",
        "        val_acc = accuracy_score(all_targets.numpy(), val_pred.numpy())\n",
        "        try:\n",
        "            val_auc = roc_auc_score(all_targets.numpy(), val_probs.numpy())\n",
        "        except ValueError:\n",
        "            val_auc = 0.0\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch}: \"\n",
        "            f\"Train Loss {avg_train_loss:.4f} | \"\n",
        "            f\"Val Loss {avg_val_loss:.4f} | \"\n",
        "            f\"Val Acc {val_acc:.4f} | \"\n",
        "            f\"Val ROC-AUC {val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        #  Early stopping\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, best_val_auc\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameter search space\n",
        "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    dropout_fc = trial.suggest_categorical(\"dropout_fc\", [0.0, 0.3, 0.5])\n",
        "    fc_hidden_dim = trial.suggest_categorical(\"fc_hidden_dim\", [0, 64, 128, 256])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "\n",
        "    model = ResNet18Custom(\n",
        "        n_view_positions=n_view_positions,\n",
        "        view_emb_dim=8,\n",
        "        fc_hidden_dim=fc_hidden_dim,\n",
        "        dropout_fc=dropout_fc,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model, best_val_auc = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        num_epochs=15,\n",
        "        early_stopping_patience=3,\n",
        "    )\n",
        "\n",
        "    return best_val_auc\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best validation ROC-AUC:\", study.best_value)\n",
        "\n",
        "\n",
        "best_params = study.best_params\n",
        "print(\"Training final ResNet-18 model with best params:\", best_params)\n",
        "\n",
        "val_dataset  = XrayImageDataset(val_df,  augment=False)\n",
        "test_dataset = XrayImageDataset(test_df, augment=False)\n",
        "\n",
        "val_loader  = DataLoader(val_dataset,  batch_size=best_params[\"batch_size\"], shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
        "\n",
        "train_val_df = pd.concat([train_df, val_df]).reset_index(drop=True)\n",
        "train_val_dataset = XrayImageDataset(train_val_df, augment=True)\n",
        "train_val_loader  = DataLoader(\n",
        "    train_val_dataset,\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Build final model\n",
        "final_model = ResNet18Custom(\n",
        "    n_view_positions=n_view_positions,\n",
        "    view_emb_dim=8,\n",
        "    fc_hidden_dim=best_params[\"fc_hidden_dim\"],\n",
        "    dropout_fc=best_params[\"dropout_fc\"],\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    final_model.parameters(),\n",
        "    lr=best_params[\"learning_rate\"],\n",
        "    weight_decay=best_params.get(\"weight_decay\", 0.0),\n",
        ")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Train final model\n",
        "final_model, _ = train_model(\n",
        "    model=final_model,\n",
        "    train_loader=train_val_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    num_epochs=10,\n",
        "    early_stopping_patience=3,\n",
        ")\n",
        "\n",
        "# Test evaluation\n",
        "final_model.eval()\n",
        "all_logits = []\n",
        "all_labels = []\n",
        "test_loss_sum = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y, view_ids in test_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        view_ids = view_ids.to(device)\n",
        "\n",
        "        logits = final_model(X, view_ids)\n",
        "        loss = criterion(logits.view(-1), y)\n",
        "        test_loss_sum += loss.item() * X.size(0)\n",
        "\n",
        "        all_logits.append(logits.view(-1).cpu())\n",
        "        all_labels.append(y.cpu())\n",
        "\n",
        "all_logits = torch.cat(all_logits)\n",
        "all_labels = torch.cat(all_labels)\n",
        "\n",
        "test_loss = test_loss_sum / len(test_loader.dataset)\n",
        "test_probs = torch.sigmoid(all_logits)\n",
        "test_pred  = (test_probs >= 0.5).int()\n",
        "\n",
        "test_acc  = accuracy_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_prec = precision_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_rec  = recall_score(all_labels.numpy(), test_pred.numpy())\n",
        "test_f1   = f1_score(all_labels.numpy(), test_pred.numpy())\n",
        "try:\n",
        "    test_auc = roc_auc_score(all_labels.numpy(), test_probs.numpy())\n",
        "except ValueError:\n",
        "    test_auc = 0.0\n",
        "\n",
        "cm = confusion_matrix(all_labels.numpy(), test_pred.numpy())\n",
        "report = classification_report(all_labels.numpy(), test_pred.numpy(),\n",
        "                               target_names=[\"Normal\", \"Pneumonia\"])\n",
        "\n",
        "print(f\"\\n=== Test Results ===\")\n",
        "print(f\"Test Loss:      {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"Test ROC-AUC:   {test_auc:.4f}\")\n",
        "print(f\"Test Precision: {test_prec:.4f}\")\n",
        "print(f\"Test Recall:    {test_rec:.4f}\")\n",
        "print(f\"Test F1-score:  {test_f1:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uTMnRpfzpIt",
        "outputId": "7c1a436d-0620-4bb5-ff0e-88d84394ec0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:15:32,135] A new study created in memory with name: no-name-94a3b13a-270b-4ed2-ba2e-16a5182d1d02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of distinct view positions: 2\n",
            "Train size: 1734, Val size: 372, Test size: 372\n",
            "Train label distribution:\n",
            " Pneumonia\n",
            "0    0.531142\n",
            "1    0.468858\n",
            "Name: proportion, dtype: float64\n",
            "Val label distribution:\n",
            " Pneumonia\n",
            "0    0.52957\n",
            "1    0.47043\n",
            "Name: proportion, dtype: float64\n",
            "Test label distribution:\n",
            " Pneumonia\n",
            "0    0.532258\n",
            "1    0.467742\n",
            "Name: proportion, dtype: float64\n",
            "Using device: cuda\n",
            "Epoch 1: Train Loss 0.6919 | Val Loss 0.6855 | Val Acc 0.5591 | Val ROC-AUC 0.5780\n",
            "Epoch 2: Train Loss 0.6812 | Val Loss 0.6984 | Val Acc 0.5457 | Val ROC-AUC 0.5791\n",
            "Epoch 3: Train Loss 0.6727 | Val Loss 0.6749 | Val Acc 0.5484 | Val ROC-AUC 0.6265\n",
            "Epoch 4: Train Loss 0.6639 | Val Loss 0.6907 | Val Acc 0.5538 | Val ROC-AUC 0.6209\n",
            "Epoch 5: Train Loss 0.6585 | Val Loss 0.6959 | Val Acc 0.5618 | Val ROC-AUC 0.6138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:16:53,619] Trial 0 finished with value: 0.6265409717186367 and parameters: {'learning_rate': 1.1099458182818129e-05, 'batch_size': 32, 'dropout_fc': 0.0, 'fc_hidden_dim': 0, 'weight_decay': 9.600574798366024e-06}. Best is trial 0 with value: 0.6265409717186367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6544 | Val Loss 0.7078 | Val Acc 0.5699 | Val ROC-AUC 0.6080\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.7017 | Val Loss 0.6895 | Val Acc 0.5565 | Val ROC-AUC 0.5374\n",
            "Epoch 2: Train Loss 0.6913 | Val Loss 0.6918 | Val Acc 0.5027 | Val ROC-AUC 0.5279\n",
            "Epoch 3: Train Loss 0.6876 | Val Loss 0.7136 | Val Acc 0.4704 | Val ROC-AUC 0.5956\n",
            "Epoch 4: Train Loss 0.6893 | Val Loss 0.6900 | Val Acc 0.5296 | Val ROC-AUC 0.5577\n",
            "Epoch 5: Train Loss 0.6892 | Val Loss 0.6944 | Val Acc 0.5081 | Val ROC-AUC 0.5095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:18:10,007] Trial 1 finished with value: 0.5955910079767949 and parameters: {'learning_rate': 0.0008222883331103353, 'batch_size': 16, 'dropout_fc': 0.3, 'fc_hidden_dim': 64, 'weight_decay': 9.393866191827285e-05}. Best is trial 0 with value: 0.6265409717186367.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6885 | Val Loss 0.6928 | Val Acc 0.5296 | Val ROC-AUC 0.4808\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6908 | Val Loss 0.7140 | Val Acc 0.5323 | Val ROC-AUC 0.5776\n",
            "Epoch 2: Train Loss 0.6795 | Val Loss 0.6890 | Val Acc 0.5457 | Val ROC-AUC 0.5610\n",
            "Epoch 3: Train Loss 0.6702 | Val Loss 0.6763 | Val Acc 0.5968 | Val ROC-AUC 0.6312\n",
            "Epoch 4: Train Loss 0.6695 | Val Loss 0.6741 | Val Acc 0.5887 | Val ROC-AUC 0.6159\n",
            "Epoch 5: Train Loss 0.6614 | Val Loss 0.6716 | Val Acc 0.5591 | Val ROC-AUC 0.6034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:19:26,397] Trial 2 finished with value: 0.631211022480058 and parameters: {'learning_rate': 8.83660741853247e-05, 'batch_size': 16, 'dropout_fc': 0.0, 'fc_hidden_dim': 256, 'weight_decay': 7.72686243275251e-06}. Best is trial 2 with value: 0.631211022480058.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss 0.6563 | Val Loss 0.7039 | Val Acc 0.5269 | Val ROC-AUC 0.5427\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6900 | Val Loss 0.6660 | Val Acc 0.5753 | Val ROC-AUC 0.6352\n",
            "Epoch 2: Train Loss 0.6749 | Val Loss 0.6586 | Val Acc 0.5941 | Val ROC-AUC 0.6385\n",
            "Epoch 3: Train Loss 0.6656 | Val Loss 0.6675 | Val Acc 0.5887 | Val ROC-AUC 0.6354\n",
            "Epoch 4: Train Loss 0.6664 | Val Loss 0.6778 | Val Acc 0.5591 | Val ROC-AUC 0.6038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:20:29,799] Trial 3 finished with value: 0.6385206671501088 and parameters: {'learning_rate': 3.2935644657250855e-05, 'batch_size': 16, 'dropout_fc': 0.0, 'fc_hidden_dim': 0, 'weight_decay': 0.0005508057884210796}. Best is trial 3 with value: 0.6385206671501088.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6560 | Val Loss 0.7210 | Val Acc 0.5645 | Val ROC-AUC 0.5841\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.7057 | Val Loss 0.7042 | Val Acc 0.4704 | Val ROC-AUC 0.4730\n",
            "Epoch 2: Train Loss 0.6930 | Val Loss 0.7056 | Val Acc 0.5296 | Val ROC-AUC 0.4958\n",
            "Epoch 3: Train Loss 0.6932 | Val Loss 0.6885 | Val Acc 0.5457 | Val ROC-AUC 0.5565\n",
            "Epoch 4: Train Loss 0.6914 | Val Loss 0.6900 | Val Acc 0.5430 | Val ROC-AUC 0.5395\n",
            "Epoch 5: Train Loss 0.6881 | Val Loss 0.6887 | Val Acc 0.5565 | Val ROC-AUC 0.5801\n",
            "Epoch 6: Train Loss 0.6911 | Val Loss 0.6860 | Val Acc 0.5296 | Val ROC-AUC 0.5756\n",
            "Epoch 7: Train Loss 0.6868 | Val Loss 0.6848 | Val Acc 0.5296 | Val ROC-AUC 0.5855\n",
            "Epoch 8: Train Loss 0.6852 | Val Loss 0.6912 | Val Acc 0.4892 | Val ROC-AUC 0.5131\n",
            "Epoch 9: Train Loss 0.6850 | Val Loss 0.6845 | Val Acc 0.5511 | Val ROC-AUC 0.5838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:22:57,710] Trial 4 finished with value: 0.5854677302393038 and parameters: {'learning_rate': 0.0007997850306772976, 'batch_size': 8, 'dropout_fc': 0.3, 'fc_hidden_dim': 64, 'weight_decay': 5.476252033199674e-06}. Best is trial 3 with value: 0.6385206671501088.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss 0.6916 | Val Loss 0.6873 | Val Acc 0.5753 | Val ROC-AUC 0.5712\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6979 | Val Loss 0.7211 | Val Acc 0.4704 | Val ROC-AUC 0.5608\n",
            "Epoch 2: Train Loss 0.6867 | Val Loss 0.7152 | Val Acc 0.4892 | Val ROC-AUC 0.5729\n",
            "Epoch 3: Train Loss 0.6760 | Val Loss 0.6893 | Val Acc 0.5269 | Val ROC-AUC 0.6026\n",
            "Epoch 4: Train Loss 0.6680 | Val Loss 0.6700 | Val Acc 0.6022 | Val ROC-AUC 0.6209\n",
            "Epoch 5: Train Loss 0.6595 | Val Loss 0.6693 | Val Acc 0.5753 | Val ROC-AUC 0.6205\n",
            "Epoch 6: Train Loss 0.6529 | Val Loss 0.6683 | Val Acc 0.5403 | Val ROC-AUC 0.6422\n",
            "Epoch 7: Train Loss 0.6496 | Val Loss 0.6639 | Val Acc 0.5860 | Val ROC-AUC 0.6327\n",
            "Epoch 8: Train Loss 0.6441 | Val Loss 0.6663 | Val Acc 0.6129 | Val ROC-AUC 0.6451\n",
            "Epoch 9: Train Loss 0.6325 | Val Loss 0.6602 | Val Acc 0.5672 | Val ROC-AUC 0.6370\n",
            "Epoch 10: Train Loss 0.6333 | Val Loss 0.6808 | Val Acc 0.5645 | Val ROC-AUC 0.6069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:25:26,683] Trial 5 finished with value: 0.6451051486584481 and parameters: {'learning_rate': 1.1086867636100034e-05, 'batch_size': 32, 'dropout_fc': 0.3, 'fc_hidden_dim': 0, 'weight_decay': 3.2069448882854284e-06}. Best is trial 5 with value: 0.6451051486584481.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss 0.6241 | Val Loss 0.7464 | Val Acc 0.5618 | Val ROC-AUC 0.6388\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6977 | Val Loss 0.6847 | Val Acc 0.5753 | Val ROC-AUC 0.5810\n",
            "Epoch 2: Train Loss 0.6874 | Val Loss 0.6906 | Val Acc 0.5296 | Val ROC-AUC 0.5649\n",
            "Epoch 3: Train Loss 0.6890 | Val Loss 0.6866 | Val Acc 0.5349 | Val ROC-AUC 0.5635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:26:25,909] Trial 6 finished with value: 0.5809717186366932 and parameters: {'learning_rate': 0.0003652709997425757, 'batch_size': 8, 'dropout_fc': 0.0, 'fc_hidden_dim': 128, 'weight_decay': 6.401247292878296e-05}. Best is trial 5 with value: 0.6451051486584481.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss 0.6863 | Val Loss 0.6894 | Val Acc 0.5269 | Val ROC-AUC 0.5439\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6894 | Val Loss 0.6870 | Val Acc 0.5376 | Val ROC-AUC 0.5563\n",
            "Epoch 2: Train Loss 0.6866 | Val Loss 0.6840 | Val Acc 0.5726 | Val ROC-AUC 0.5972\n",
            "Epoch 3: Train Loss 0.6772 | Val Loss 0.6740 | Val Acc 0.5860 | Val ROC-AUC 0.6164\n",
            "Epoch 4: Train Loss 0.6696 | Val Loss 0.6702 | Val Acc 0.5833 | Val ROC-AUC 0.6321\n",
            "Epoch 5: Train Loss 0.6622 | Val Loss 0.6859 | Val Acc 0.5699 | Val ROC-AUC 0.6312\n",
            "Epoch 6: Train Loss 0.6607 | Val Loss 0.6662 | Val Acc 0.5672 | Val ROC-AUC 0.6297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:27:59,640] Trial 7 finished with value: 0.6321102248005802 and parameters: {'learning_rate': 1.4323582185264878e-05, 'batch_size': 32, 'dropout_fc': 0.3, 'fc_hidden_dim': 256, 'weight_decay': 0.00034471487373244743}. Best is trial 5 with value: 0.6451051486584481.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss 0.6530 | Val Loss 0.7365 | Val Acc 0.5565 | Val ROC-AUC 0.6316\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6963 | Val Loss 0.6902 | Val Acc 0.5054 | Val ROC-AUC 0.5462\n",
            "Epoch 2: Train Loss 0.6870 | Val Loss 0.6874 | Val Acc 0.5591 | Val ROC-AUC 0.6125\n",
            "Epoch 3: Train Loss 0.6800 | Val Loss 0.6721 | Val Acc 0.5806 | Val ROC-AUC 0.6187\n",
            "Epoch 4: Train Loss 0.6739 | Val Loss 0.6737 | Val Acc 0.5753 | Val ROC-AUC 0.6159\n",
            "Epoch 5: Train Loss 0.6687 | Val Loss 0.6852 | Val Acc 0.5511 | Val ROC-AUC 0.6334\n",
            "Epoch 6: Train Loss 0.6649 | Val Loss 0.6648 | Val Acc 0.5753 | Val ROC-AUC 0.6527\n",
            "Epoch 7: Train Loss 0.6586 | Val Loss 0.6842 | Val Acc 0.5645 | Val ROC-AUC 0.6283\n",
            "Epoch 8: Train Loss 0.6471 | Val Loss 0.6741 | Val Acc 0.5780 | Val ROC-AUC 0.6253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:30:00,591] Trial 8 finished with value: 0.652675852066715 and parameters: {'learning_rate': 2.1318743371466283e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 64, 'weight_decay': 1.7457588051381907e-05}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss 0.6482 | Val Loss 0.6667 | Val Acc 0.5995 | Val ROC-AUC 0.6353\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6932 | Val Loss 0.6770 | Val Acc 0.5941 | Val ROC-AUC 0.6160\n",
            "Epoch 2: Train Loss 0.6906 | Val Loss 0.7358 | Val Acc 0.5081 | Val ROC-AUC 0.6193\n",
            "Epoch 3: Train Loss 0.6806 | Val Loss 0.6673 | Val Acc 0.6102 | Val ROC-AUC 0.6256\n",
            "Epoch 4: Train Loss 0.6820 | Val Loss 0.6725 | Val Acc 0.5618 | Val ROC-AUC 0.6294\n",
            "Epoch 5: Train Loss 0.6783 | Val Loss 0.6837 | Val Acc 0.5457 | Val ROC-AUC 0.5916\n",
            "Epoch 6: Train Loss 0.6780 | Val Loss 0.6839 | Val Acc 0.5618 | Val ROC-AUC 0.5997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:31:44,609] Trial 9 finished with value: 0.6294416243654821 and parameters: {'learning_rate': 0.00014683524896389263, 'batch_size': 8, 'dropout_fc': 0.3, 'fc_hidden_dim': 256, 'weight_decay': 2.7949354466569924e-06}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss 0.6726 | Val Loss 0.6900 | Val Acc 0.5618 | Val ROC-AUC 0.6074\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6894 | Val Loss 0.6839 | Val Acc 0.5699 | Val ROC-AUC 0.5804\n",
            "Epoch 2: Train Loss 0.6839 | Val Loss 0.6700 | Val Acc 0.5699 | Val ROC-AUC 0.6417\n",
            "Epoch 3: Train Loss 0.6720 | Val Loss 0.6828 | Val Acc 0.5618 | Val ROC-AUC 0.5983\n",
            "Epoch 4: Train Loss 0.6632 | Val Loss 0.6646 | Val Acc 0.5780 | Val ROC-AUC 0.6347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:32:51,728] Trial 10 finished with value: 0.6416823785351704 and parameters: {'learning_rate': 3.9430365949371704e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 64, 'weight_decay': 1.028599413279347e-06}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6606 | Val Loss 0.6895 | Val Acc 0.5511 | Val ROC-AUC 0.5978\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6865 | Val Loss 0.6970 | Val Acc 0.5323 | Val ROC-AUC 0.5863\n",
            "Epoch 2: Train Loss 0.6761 | Val Loss 0.7040 | Val Acc 0.5591 | Val ROC-AUC 0.5904\n",
            "Epoch 3: Train Loss 0.6621 | Val Loss 0.8262 | Val Acc 0.5349 | Val ROC-AUC 0.6219\n",
            "Epoch 4: Train Loss 0.6545 | Val Loss 0.8790 | Val Acc 0.5323 | Val ROC-AUC 0.6319\n",
            "Epoch 5: Train Loss 0.6420 | Val Loss 0.7012 | Val Acc 0.5699 | Val ROC-AUC 0.6253\n",
            "Epoch 6: Train Loss 0.6400 | Val Loss 0.6631 | Val Acc 0.5726 | Val ROC-AUC 0.6292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:34:25,758] Trial 11 finished with value: 0.6319361856417693 and parameters: {'learning_rate': 2.4844752513589102e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 0, 'weight_decay': 1.9001366181085305e-05}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss 0.6416 | Val Loss 0.7157 | Val Acc 0.5672 | Val ROC-AUC 0.6263\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6976 | Val Loss 0.6884 | Val Acc 0.5726 | Val ROC-AUC 0.5610\n",
            "Epoch 2: Train Loss 0.6931 | Val Loss 0.6858 | Val Acc 0.5565 | Val ROC-AUC 0.5597\n",
            "Epoch 3: Train Loss 0.6878 | Val Loss 0.6813 | Val Acc 0.5806 | Val ROC-AUC 0.5942\n",
            "Epoch 4: Train Loss 0.6802 | Val Loss 0.6788 | Val Acc 0.5591 | Val ROC-AUC 0.6210\n",
            "Epoch 5: Train Loss 0.6764 | Val Loss 0.6730 | Val Acc 0.5753 | Val ROC-AUC 0.6152\n",
            "Epoch 6: Train Loss 0.6689 | Val Loss 0.6673 | Val Acc 0.5941 | Val ROC-AUC 0.6296\n",
            "Epoch 7: Train Loss 0.6635 | Val Loss 0.6689 | Val Acc 0.5833 | Val ROC-AUC 0.6206\n",
            "Epoch 8: Train Loss 0.6604 | Val Loss 0.6607 | Val Acc 0.5806 | Val ROC-AUC 0.6413\n",
            "Epoch 9: Train Loss 0.6574 | Val Loss 0.6664 | Val Acc 0.5726 | Val ROC-AUC 0.6293\n",
            "Epoch 10: Train Loss 0.6547 | Val Loss 0.6811 | Val Acc 0.5941 | Val ROC-AUC 0.6463\n",
            "Epoch 11: Train Loss 0.6449 | Val Loss 0.6659 | Val Acc 0.5726 | Val ROC-AUC 0.6347\n",
            "Epoch 12: Train Loss 0.6448 | Val Loss 0.7031 | Val Acc 0.5726 | Val ROC-AUC 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:37:20,612] Trial 12 finished with value: 0.6462654097171864 and parameters: {'learning_rate': 1.0864963251324886e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 1.684839360675428e-06}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss 0.6407 | Val Loss 0.6902 | Val Acc 0.5565 | Val ROC-AUC 0.6415\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6936 | Val Loss 0.6815 | Val Acc 0.5860 | Val ROC-AUC 0.6028\n",
            "Epoch 2: Train Loss 0.6799 | Val Loss 0.6753 | Val Acc 0.5914 | Val ROC-AUC 0.6197\n",
            "Epoch 3: Train Loss 0.6695 | Val Loss 0.6746 | Val Acc 0.5538 | Val ROC-AUC 0.6100\n",
            "Epoch 4: Train Loss 0.6642 | Val Loss 0.6902 | Val Acc 0.5457 | Val ROC-AUC 0.5895\n",
            "Epoch 5: Train Loss 0.6595 | Val Loss 0.6629 | Val Acc 0.5887 | Val ROC-AUC 0.6321\n",
            "Epoch 6: Train Loss 0.6503 | Val Loss 0.6598 | Val Acc 0.5860 | Val ROC-AUC 0.6443\n",
            "Epoch 7: Train Loss 0.6478 | Val Loss 0.7183 | Val Acc 0.5753 | Val ROC-AUC 0.6285\n",
            "Epoch 8: Train Loss 0.6453 | Val Loss 0.6776 | Val Acc 0.5726 | Val ROC-AUC 0.6000\n",
            "Epoch 9: Train Loss 0.6478 | Val Loss 0.6922 | Val Acc 0.5726 | Val ROC-AUC 0.6504\n",
            "Epoch 10: Train Loss 0.6398 | Val Loss 0.7095 | Val Acc 0.5753 | Val ROC-AUC 0.6500\n",
            "Epoch 11: Train Loss 0.6379 | Val Loss 0.6567 | Val Acc 0.5860 | Val ROC-AUC 0.6487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:40:01,258] Trial 13 finished with value: 0.6503553299492386 and parameters: {'learning_rate': 5.7344694950519527e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 1.060662325747196e-06}. Best is trial 8 with value: 0.652675852066715.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss 0.6297 | Val Loss 0.7464 | Val Acc 0.5699 | Val ROC-AUC 0.6200\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6904 | Val Loss 0.7246 | Val Acc 0.5376 | Val ROC-AUC 0.6116\n",
            "Epoch 2: Train Loss 0.6798 | Val Loss 0.6885 | Val Acc 0.5376 | Val ROC-AUC 0.6134\n",
            "Epoch 3: Train Loss 0.6669 | Val Loss 0.6698 | Val Acc 0.5887 | Val ROC-AUC 0.6124\n",
            "Epoch 4: Train Loss 0.6668 | Val Loss 0.6548 | Val Acc 0.6129 | Val ROC-AUC 0.6532\n",
            "Epoch 5: Train Loss 0.6590 | Val Loss 0.6611 | Val Acc 0.5806 | Val ROC-AUC 0.6454\n",
            "Epoch 6: Train Loss 0.6528 | Val Loss 0.6601 | Val Acc 0.5914 | Val ROC-AUC 0.6409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:41:30,980] Trial 14 finished with value: 0.6531979695431471 and parameters: {'learning_rate': 8.496725313587672e-05, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 3.0346862390374634e-05}. Best is trial 14 with value: 0.6531979695431471.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss 0.6512 | Val Loss 0.6564 | Val Acc 0.6102 | Val ROC-AUC 0.6513\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6958 | Val Loss 0.6827 | Val Acc 0.5806 | Val ROC-AUC 0.5820\n",
            "Epoch 2: Train Loss 0.6812 | Val Loss 0.7442 | Val Acc 0.5376 | Val ROC-AUC 0.5799\n",
            "Epoch 3: Train Loss 0.6819 | Val Loss 0.7541 | Val Acc 0.5323 | Val ROC-AUC 0.5638\n",
            "Epoch 4: Train Loss 0.6816 | Val Loss 0.6778 | Val Acc 0.5618 | Val ROC-AUC 0.5916\n",
            "Epoch 5: Train Loss 0.6707 | Val Loss 0.6942 | Val Acc 0.5484 | Val ROC-AUC 0.5670\n",
            "Epoch 6: Train Loss 0.6709 | Val Loss 0.6870 | Val Acc 0.5753 | Val ROC-AUC 0.5999\n",
            "Epoch 7: Train Loss 0.6648 | Val Loss 0.6721 | Val Acc 0.5753 | Val ROC-AUC 0.6103\n",
            "Epoch 8: Train Loss 0.6644 | Val Loss 0.6787 | Val Acc 0.5672 | Val ROC-AUC 0.6008\n",
            "Epoch 9: Train Loss 0.6714 | Val Loss 0.6934 | Val Acc 0.5484 | Val ROC-AUC 0.5808\n",
            "Epoch 10: Train Loss 0.6647 | Val Loss 0.6993 | Val Acc 0.5618 | Val ROC-AUC 0.6147\n",
            "Epoch 11: Train Loss 0.6611 | Val Loss 0.8195 | Val Acc 0.5457 | Val ROC-AUC 0.5736\n",
            "Epoch 12: Train Loss 0.6604 | Val Loss 0.6722 | Val Acc 0.5672 | Val ROC-AUC 0.6184\n",
            "Epoch 13: Train Loss 0.6565 | Val Loss 0.7093 | Val Acc 0.5565 | Val ROC-AUC 0.6326\n",
            "Epoch 14: Train Loss 0.6560 | Val Loss 0.6916 | Val Acc 0.5806 | Val ROC-AUC 0.6303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:44:51,796] Trial 15 finished with value: 0.6591443074691806 and parameters: {'learning_rate': 0.000203735992061931, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 5.513772513711078e-05}. Best is trial 15 with value: 0.6591443074691806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss 0.6551 | Val Loss 0.6516 | Val Acc 0.6075 | Val ROC-AUC 0.6591\n",
            "Epoch 1: Train Loss 0.6980 | Val Loss 0.6821 | Val Acc 0.5511 | Val ROC-AUC 0.5708\n",
            "Epoch 2: Train Loss 0.6922 | Val Loss 0.9239 | Val Acc 0.5296 | Val ROC-AUC 0.5964\n",
            "Epoch 3: Train Loss 0.6758 | Val Loss 0.7426 | Val Acc 0.5484 | Val ROC-AUC 0.5923\n",
            "Epoch 4: Train Loss 0.6712 | Val Loss 0.7052 | Val Acc 0.5188 | Val ROC-AUC 0.5631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:45:58,708] Trial 16 finished with value: 0.59643219724438 and parameters: {'learning_rate': 0.000193429421741171, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 9.284813717656511e-05}. Best is trial 15 with value: 0.6591443074691806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss 0.6723 | Val Loss 0.6905 | Val Acc 0.5565 | Val ROC-AUC 0.5827\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6936 | Val Loss 0.6999 | Val Acc 0.5242 | Val ROC-AUC 0.5823\n",
            "Epoch 2: Train Loss 0.6845 | Val Loss 0.7191 | Val Acc 0.5484 | Val ROC-AUC 0.5710\n",
            "Epoch 3: Train Loss 0.6857 | Val Loss 0.6888 | Val Acc 0.5591 | Val ROC-AUC 0.5562\n",
            "Epoch 4: Train Loss 0.6747 | Val Loss 0.6913 | Val Acc 0.5565 | Val ROC-AUC 0.6054\n",
            "Epoch 5: Train Loss 0.6758 | Val Loss 0.7048 | Val Acc 0.4624 | Val ROC-AUC 0.5403\n",
            "Epoch 6: Train Loss 0.6742 | Val Loss 0.6846 | Val Acc 0.5645 | Val ROC-AUC 0.5541\n",
            "Epoch 7: Train Loss 0.6772 | Val Loss 0.6788 | Val Acc 0.5645 | Val ROC-AUC 0.6132\n",
            "Epoch 8: Train Loss 0.6656 | Val Loss 0.6787 | Val Acc 0.5780 | Val ROC-AUC 0.6076\n",
            "Epoch 9: Train Loss 0.6663 | Val Loss 0.6780 | Val Acc 0.5565 | Val ROC-AUC 0.6109\n",
            "Epoch 10: Train Loss 0.6732 | Val Loss 0.6682 | Val Acc 0.6022 | Val ROC-AUC 0.6435\n",
            "Epoch 11: Train Loss 0.6636 | Val Loss 0.6643 | Val Acc 0.5833 | Val ROC-AUC 0.6363\n",
            "Epoch 12: Train Loss 0.6651 | Val Loss 0.7808 | Val Acc 0.5376 | Val ROC-AUC 0.5459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:48:52,209] Trial 17 finished with value: 0.6435097897026831 and parameters: {'learning_rate': 0.00027195407455455343, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 0.00019699355069100326}. Best is trial 15 with value: 0.6591443074691806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss 0.6676 | Val Loss 0.7187 | Val Acc 0.5081 | Val ROC-AUC 0.6082\n",
            "Early stopping triggered.\n",
            "Epoch 1: Train Loss 0.6969 | Val Loss 0.6897 | Val Acc 0.5054 | Val ROC-AUC 0.5201\n",
            "Epoch 2: Train Loss 0.6830 | Val Loss 0.6846 | Val Acc 0.5565 | Val ROC-AUC 0.5802\n",
            "Epoch 3: Train Loss 0.6823 | Val Loss 0.6788 | Val Acc 0.5645 | Val ROC-AUC 0.5917\n",
            "Epoch 4: Train Loss 0.6758 | Val Loss 0.6719 | Val Acc 0.5914 | Val ROC-AUC 0.6067\n",
            "Epoch 5: Train Loss 0.6717 | Val Loss 0.7045 | Val Acc 0.5645 | Val ROC-AUC 0.5935\n",
            "Epoch 6: Train Loss 0.6706 | Val Loss 0.6771 | Val Acc 0.5349 | Val ROC-AUC 0.6013\n",
            "Epoch 7: Train Loss 0.6682 | Val Loss 0.7031 | Val Acc 0.5511 | Val ROC-AUC 0.6157\n",
            "Epoch 8: Train Loss 0.6717 | Val Loss 0.6732 | Val Acc 0.5699 | Val ROC-AUC 0.6098\n",
            "Epoch 9: Train Loss 0.6731 | Val Loss 0.6739 | Val Acc 0.5565 | Val ROC-AUC 0.6006\n",
            "Epoch 10: Train Loss 0.6705 | Val Loss 0.6617 | Val Acc 0.5753 | Val ROC-AUC 0.6436\n",
            "Epoch 11: Train Loss 0.6592 | Val Loss 0.6793 | Val Acc 0.5995 | Val ROC-AUC 0.6236\n",
            "Epoch 12: Train Loss 0.6599 | Val Loss 0.6640 | Val Acc 0.5672 | Val ROC-AUC 0.6328\n",
            "Epoch 13: Train Loss 0.6615 | Val Loss 0.6534 | Val Acc 0.6183 | Val ROC-AUC 0.6586\n",
            "Epoch 14: Train Loss 0.6609 | Val Loss 0.6649 | Val Acc 0.5995 | Val ROC-AUC 0.6437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:52:33,839] Trial 18 finished with value: 0.6585641769398115 and parameters: {'learning_rate': 8.584901857613793e-05, 'batch_size': 8, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 3.756748704136713e-05}. Best is trial 15 with value: 0.6591443074691806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss 0.6455 | Val Loss 0.6691 | Val Acc 0.5699 | Val ROC-AUC 0.6351\n",
            "Epoch 1: Train Loss 0.6974 | Val Loss 0.6894 | Val Acc 0.5699 | Val ROC-AUC 0.5334\n",
            "Epoch 2: Train Loss 0.6945 | Val Loss 0.6942 | Val Acc 0.4812 | Val ROC-AUC 0.5269\n",
            "Epoch 3: Train Loss 0.6905 | Val Loss 0.6922 | Val Acc 0.5296 | Val ROC-AUC 0.5441\n",
            "Epoch 4: Train Loss 0.6909 | Val Loss 0.6912 | Val Acc 0.5269 | Val ROC-AUC 0.5245\n",
            "Epoch 5: Train Loss 0.6892 | Val Loss 0.6898 | Val Acc 0.4731 | Val ROC-AUC 0.5225\n",
            "Epoch 6: Train Loss 0.6892 | Val Loss 0.6899 | Val Acc 0.5161 | Val ROC-AUC 0.5581\n",
            "Epoch 7: Train Loss 0.6865 | Val Loss 0.6884 | Val Acc 0.5296 | Val ROC-AUC 0.5670\n",
            "Epoch 8: Train Loss 0.6844 | Val Loss 0.6853 | Val Acc 0.5565 | Val ROC-AUC 0.5702\n",
            "Epoch 9: Train Loss 0.6855 | Val Loss 0.6843 | Val Acc 0.5672 | Val ROC-AUC 0.5679\n",
            "Epoch 10: Train Loss 0.6816 | Val Loss 0.6969 | Val Acc 0.5188 | Val ROC-AUC 0.5880\n",
            "Epoch 11: Train Loss 0.6887 | Val Loss 0.6911 | Val Acc 0.5296 | Val ROC-AUC 0.5172\n",
            "Epoch 12: Train Loss 0.6870 | Val Loss 0.6898 | Val Acc 0.5242 | Val ROC-AUC 0.5261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-08 21:55:45,946] Trial 19 finished with value: 0.5880203045685279 and parameters: {'learning_rate': 0.00042270642458186935, 'batch_size': 8, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 5.389741352273169e-05}. Best is trial 15 with value: 0.6591443074691806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss 0.6854 | Val Loss 0.6912 | Val Acc 0.5484 | Val ROC-AUC 0.5335\n",
            "Early stopping triggered.\n",
            "Best hyperparameters: {'learning_rate': 0.000203735992061931, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 5.513772513711078e-05}\n",
            "Best validation ROC-AUC: 0.6591443074691806\n",
            "Training final ResNet-18 model with best params: {'learning_rate': 0.000203735992061931, 'batch_size': 32, 'dropout_fc': 0.5, 'fc_hidden_dim': 128, 'weight_decay': 5.513772513711078e-05}\n",
            "Epoch 1: Train Loss 0.6966 | Val Loss 0.6779 | Val Acc 0.5618 | Val ROC-AUC 0.6128\n",
            "Epoch 2: Train Loss 0.6783 | Val Loss 0.6790 | Val Acc 0.5968 | Val ROC-AUC 0.5968\n",
            "Epoch 3: Train Loss 0.6789 | Val Loss 0.6680 | Val Acc 0.5753 | Val ROC-AUC 0.6422\n",
            "Epoch 4: Train Loss 0.6764 | Val Loss 0.6992 | Val Acc 0.4892 | Val ROC-AUC 0.5890\n",
            "Epoch 5: Train Loss 0.6762 | Val Loss 0.6720 | Val Acc 0.6102 | Val ROC-AUC 0.6305\n",
            "Epoch 6: Train Loss 0.6722 | Val Loss 0.6586 | Val Acc 0.5941 | Val ROC-AUC 0.6403\n",
            "Early stopping triggered.\n",
            "\n",
            "=== Test Results ===\n",
            "Test Loss:      0.6674\n",
            "Test Accuracy:  0.5968\n",
            "Test ROC-AUC:   0.6358\n",
            "Test Precision: 0.5732\n",
            "Test Recall:    0.5402\n",
            "Test F1-score:  0.5562\n",
            "\n",
            "Confusion Matrix:\n",
            " [[128  70]\n",
            " [ 80  94]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.62      0.65      0.63       198\n",
            "   Pneumonia       0.57      0.54      0.56       174\n",
            "\n",
            "    accuracy                           0.60       372\n",
            "   macro avg       0.59      0.59      0.59       372\n",
            "weighted avg       0.60      0.60      0.60       372\n",
            "\n"
          ]
        }
      ]
    }
  ]
}